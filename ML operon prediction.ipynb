{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf28c4a-82bb-468f-ad0f-e2406cceccf4",
   "metadata": {},
   "source": [
    "This notebook is for ML operon prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a40669-ffc1-46d3-9b1a-fea3496e1818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Operonic to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000002</th>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000005</th>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000006</th>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000007</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000012</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002084</th>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002085</th>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002086</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002087</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002088</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Distance to IUN  Operonic to IUN  \\\n",
       "Protein ID                                                      \n",
       "pgap_GCF_000220135.1_000002              575                0   \n",
       "pgap_GCF_000220135.1_000005              134                0   \n",
       "pgap_GCF_000220135.1_000006              174                1   \n",
       "pgap_GCF_000220135.1_000007               68                1   \n",
       "pgap_GCF_000220135.1_000012              105                0   \n",
       "...                                      ...              ...   \n",
       "pgap_GCF_000220135.1_002084              123                1   \n",
       "pgap_GCF_000220135.1_002085              122                1   \n",
       "pgap_GCF_000220135.1_002086               -1                1   \n",
       "pgap_GCF_000220135.1_002087                3                1   \n",
       "pgap_GCF_000220135.1_002088               31                1   \n",
       "\n",
       "                             Hamming Distance to IUN  \\\n",
       "Protein ID                                             \n",
       "pgap_GCF_000220135.1_000002                    0.043   \n",
       "pgap_GCF_000220135.1_000005                    0.043   \n",
       "pgap_GCF_000220135.1_000006                    0.043   \n",
       "pgap_GCF_000220135.1_000007                    0.043   \n",
       "pgap_GCF_000220135.1_000012                    0.478   \n",
       "...                                              ...   \n",
       "pgap_GCF_000220135.1_002084                    0.130   \n",
       "pgap_GCF_000220135.1_002085                    0.130   \n",
       "pgap_GCF_000220135.1_002086                    0.000   \n",
       "pgap_GCF_000220135.1_002087                    0.087   \n",
       "pgap_GCF_000220135.1_002088                    0.087   \n",
       "\n",
       "                             GOntoSim Similarity to IUN  \\\n",
       "Protein ID                                                \n",
       "pgap_GCF_000220135.1_000002                       0.738   \n",
       "pgap_GCF_000220135.1_000005                         NaN   \n",
       "pgap_GCF_000220135.1_000006                       0.845   \n",
       "pgap_GCF_000220135.1_000007                         NaN   \n",
       "pgap_GCF_000220135.1_000012                         NaN   \n",
       "...                                                 ...   \n",
       "pgap_GCF_000220135.1_002084                         NaN   \n",
       "pgap_GCF_000220135.1_002085                         NaN   \n",
       "pgap_GCF_000220135.1_002086                         NaN   \n",
       "pgap_GCF_000220135.1_002087                         NaN   \n",
       "pgap_GCF_000220135.1_002088                       0.364   \n",
       "\n",
       "                             Wang Similarity to IUN  Upstream Terminator  \n",
       "Protein ID                                                                \n",
       "pgap_GCF_000220135.1_000002                   0.735                    1  \n",
       "pgap_GCF_000220135.1_000005                     NaN                    0  \n",
       "pgap_GCF_000220135.1_000006                   0.901                    0  \n",
       "pgap_GCF_000220135.1_000007                     NaN                    0  \n",
       "pgap_GCF_000220135.1_000012                     NaN                    0  \n",
       "...                                             ...                  ...  \n",
       "pgap_GCF_000220135.1_002084                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002085                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002086                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002087                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002088                   0.514                    0  \n",
       "\n",
       "[581 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Operonic to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581.000000</td>\n",
       "      <td>581.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>581.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>105.972461</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.132557</td>\n",
       "      <td>0.519325</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.113597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>127.496069</td>\n",
       "      <td>0.453761</td>\n",
       "      <td>0.204587</td>\n",
       "      <td>0.299486</td>\n",
       "      <td>0.344129</td>\n",
       "      <td>0.317595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>151.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.795500</td>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1308.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Distance to IUN  Operonic to IUN  Hamming Distance to IUN  \\\n",
       "count       581.000000       581.000000               528.000000   \n",
       "mean        105.972461         0.710843                 0.132557   \n",
       "std         127.496069         0.453761                 0.204587   \n",
       "min         -53.000000         0.000000                 0.000000   \n",
       "25%          15.000000         0.000000                 0.000000   \n",
       "50%          79.000000         1.000000                 0.043000   \n",
       "75%         151.000000         1.000000                 0.217000   \n",
       "max        1308.000000         1.000000                 1.000000   \n",
       "\n",
       "       GOntoSim Similarity to IUN  Wang Similarity to IUN  Upstream Terminator  \n",
       "count                  255.000000              255.000000           581.000000  \n",
       "mean                     0.519325                0.511000             0.113597  \n",
       "std                      0.299486                0.344129             0.317595  \n",
       "min                      0.098000                0.017000             0.000000  \n",
       "25%                      0.278500                0.186500             0.000000  \n",
       "50%                      0.401000                0.504000             0.000000  \n",
       "75%                      0.795500                0.861500             0.000000  \n",
       "max                      1.000000                1.000000             1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the ML data\n",
    "ml_data = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/ML/tu_input_for_ml_term.tsv\", sep=\"\\t\").drop(\"Unnamed: 0\", axis=1).set_index('Protein ID')\n",
    "display(ml_data)\n",
    "\n",
    "# Print data summary\n",
    "ml_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fca7e-d675-4183-8666-b7424370ef22",
   "metadata": {},
   "source": [
    "First, try to teach a model based on all features (distance to IUN, phylogenetic distance, semantic similarity and presence of upstream terminator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8ec28cd0-6256-4b1a-a518-2b38604fb8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.819\n",
      "CV Precision:        0.867\n",
      "CV Recall:           0.881\n",
      "CV F1‐Score:         0.874\n",
      "CV ROC AUC:          0.893\n",
      "CV Log‐Loss:         0.497\n",
      "CV Brier Score:      0.125\n",
      "CV Confusion Matrix:\n",
      " [[112  56]\n",
      " [ 49 364]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=0))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "# print(proba)\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "372c88f4-2f72-47cb-a129-298d4e45c907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000002</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000005</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000006</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000007</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000012</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002084</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002085</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002086</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002087</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002088</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Distance to IUN  Hamming Distance to IUN  \\\n",
       "Protein ID                                                              \n",
       "pgap_GCF_000220135.1_000002              575                    0.043   \n",
       "pgap_GCF_000220135.1_000005              134                    0.043   \n",
       "pgap_GCF_000220135.1_000006              174                    0.043   \n",
       "pgap_GCF_000220135.1_000007               68                    0.043   \n",
       "pgap_GCF_000220135.1_000012              105                    0.478   \n",
       "...                                      ...                      ...   \n",
       "pgap_GCF_000220135.1_002084              123                    0.130   \n",
       "pgap_GCF_000220135.1_002085              122                    0.130   \n",
       "pgap_GCF_000220135.1_002086               -1                    0.000   \n",
       "pgap_GCF_000220135.1_002087                3                    0.087   \n",
       "pgap_GCF_000220135.1_002088               31                    0.087   \n",
       "\n",
       "                             GOntoSim Similarity to IUN  \\\n",
       "Protein ID                                                \n",
       "pgap_GCF_000220135.1_000002                       0.738   \n",
       "pgap_GCF_000220135.1_000005                         NaN   \n",
       "pgap_GCF_000220135.1_000006                       0.845   \n",
       "pgap_GCF_000220135.1_000007                         NaN   \n",
       "pgap_GCF_000220135.1_000012                         NaN   \n",
       "...                                                 ...   \n",
       "pgap_GCF_000220135.1_002084                         NaN   \n",
       "pgap_GCF_000220135.1_002085                         NaN   \n",
       "pgap_GCF_000220135.1_002086                         NaN   \n",
       "pgap_GCF_000220135.1_002087                         NaN   \n",
       "pgap_GCF_000220135.1_002088                       0.364   \n",
       "\n",
       "                             Wang Similarity to IUN  Upstream Terminator  \n",
       "Protein ID                                                                \n",
       "pgap_GCF_000220135.1_000002                   0.735                    1  \n",
       "pgap_GCF_000220135.1_000005                     NaN                    0  \n",
       "pgap_GCF_000220135.1_000006                   0.901                    0  \n",
       "pgap_GCF_000220135.1_000007                     NaN                    0  \n",
       "pgap_GCF_000220135.1_000012                     NaN                    0  \n",
       "...                                             ...                  ...  \n",
       "pgap_GCF_000220135.1_002084                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002085                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002086                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002087                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002088                   0.514                    0  \n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select The Prediction Target\n",
    "y = ml_data[\"Operonic to IUN\"]\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator\"]\n",
    "X = ml_data[ml_features]\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42f3e298-15f3-4774-88e3-7c9cd8f811d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to IUN             →  0.5958\n",
      "Hamming Distance to IUN     →  0.1500\n",
      "Upstream Terminator         →  0.0970\n",
      "GOntoSim Similarity to IUN  →  0.0873\n",
      "Wang Similarity to IUN      →  0.0698\n"
     ]
    }
   ],
   "source": [
    "# Gini feature importance\n",
    "\n",
    "# After fitting your pipeline on all data:\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Extract the fitted RandomForest\n",
    "rf = pipeline.named_steps['model']\n",
    "\n",
    "# Get raw importances and pair with feature names\n",
    "importances = rf.feature_importances_\n",
    "feat_names   = X.columns  # or however you store your column names\n",
    "\n",
    "# Sort descending\n",
    "indices = importances.argsort()[::-1]\n",
    "for idx in indices:\n",
    "    print(f\"{feat_names[idx]:26s}  →  {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98ae5659-bb05-4681-ae23-e11c62ac3672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to IUN            → 0.5940 ± 0.0074\n",
      "Hamming Distance to IUN    → 0.1544 ± 0.0093\n",
      "GOntoSim Similarity to IUN → 0.0881 ± 0.0070\n",
      "Upstream Terminator        → 0.0867 ± 0.0076\n",
      "Wang Similarity to IUN     → 0.0768 ± 0.0043\n"
     ]
    }
   ],
   "source": [
    "# Gini importance with cross-validation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Prepare your pipeline (same as before)\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=0))\n",
    "])\n",
    "\n",
    "# Set up 5‑fold stratified CV\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Will hold the feature_importances_ from each fold\n",
    "all_importances = []\n",
    "\n",
    "for train_idx, _ in kf.split(X, y):\n",
    "    # Fit only on the train‐portion of each fold\n",
    "    X_tr, y_tr = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "    # Extract the fitted RF and its importances\n",
    "    rf = pipeline.named_steps['model']\n",
    "    all_importances.append(rf.feature_importances_)\n",
    "\n",
    "# Convert to array for easy aggregation\n",
    "importances_arr = np.vstack(all_importances)   # shape = (n_folds, n_features)\n",
    "\n",
    "# Compute mean and std across folds\n",
    "mean_imp = importances_arr.mean(axis=0)\n",
    "std_imp  = importances_arr.std(axis=0)\n",
    "\n",
    "# Pair with feature names and sort descending\n",
    "feat_names = X.columns\n",
    "indices = mean_imp.argsort()[::-1]\n",
    "\n",
    "for idx in indices:\n",
    "    print(f\"{feat_names[idx]:26s} → {mean_imp[idx]:.4f} ± {std_imp[idx]:.4f}\") # 26s limits str length to 26 symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0c8b1-c68b-4e33-8165-68f7a79ccea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation feature importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Split off a hold‑out set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 2) Compute permutation importances on the held‑out set\n",
    "results = permutation_importance(\n",
    "    pipeline, X_val, y_val,\n",
    "    n_repeats=30,\n",
    "    random_state=0,\n",
    "    scoring='balanced_accuracy'   # or 'roc_auc', etc.\n",
    ")\n",
    "\n",
    "# 3) Display sorted\n",
    "perm_importances = results.importances_mean\n",
    "indices = perm_importances.argsort()[::-1]\n",
    "for idx in indices:\n",
    "    mean_imp = perm_importances[idx]\n",
    "    std_imp  = results.importances_std[idx]\n",
    "    print(f\"{feat_names[idx]:20s}  →  {mean_imp:.4f} ± {std_imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9bcb68a7-5064-4d69-955f-a75edf313303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to IUN            → 0.155 ± 0.020\n",
      "Hamming Distance to IUN    → 0.029 ± 0.021\n",
      "GOntoSim Similarity to IUN → 0.008 ± 0.012\n",
      "Wang Similarity to IUN     → 0.006 ± 0.007\n",
      "Upstream Terminator        → 0.021 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "# Permutation importance with cross-validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "all_importances = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X, y):\n",
    "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "\n",
    "    # e.g. permutation importance on the hold‑out fold\n",
    "    res = permutation_importance(rf, X_val, y_val, n_repeats=10, random_state=0)\n",
    "    all_importances.append(res.importances_mean)\n",
    "\n",
    "all_importances = np.array(all_importances)\n",
    "mean_imp = np.mean(all_importances, axis=0)\n",
    "std_imp  = np.std(all_importances, axis=0)\n",
    "\n",
    "for name, m, s in zip(X.columns, mean_imp, std_imp):\n",
    "    print(f\"{name:26s} → {m:.3f} ± {s:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a59264-3481-4086-8021-243628ae4a5c",
   "metadata": {},
   "source": [
    "Since semantic similarity has low significance, it is necessary to try to remove these columns and evaluate the model based on intergenic distance, phylogenetic distances and the presence of a terminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f3e680a-0017-49a6-a376-918da1052247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protein ID\n",
       "pgap_GCF_000220135.1_000002    0\n",
       "pgap_GCF_000220135.1_000005    0\n",
       "pgap_GCF_000220135.1_000006    1\n",
       "pgap_GCF_000220135.1_000007    1\n",
       "pgap_GCF_000220135.1_000012    0\n",
       "                              ..\n",
       "pgap_GCF_000220135.1_002084    1\n",
       "pgap_GCF_000220135.1_002085    1\n",
       "pgap_GCF_000220135.1_002086    1\n",
       "pgap_GCF_000220135.1_002087    1\n",
       "pgap_GCF_000220135.1_002088    1\n",
       "Name: Operonic to IUN, Length: 581, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>Upstream Terminator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000002</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000005</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000006</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000007</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000012</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002084</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002085</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002086</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002087</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002088</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Distance to IUN  Hamming Distance to IUN  \\\n",
       "Protein ID                                                              \n",
       "pgap_GCF_000220135.1_000002              575                    0.043   \n",
       "pgap_GCF_000220135.1_000005              134                    0.043   \n",
       "pgap_GCF_000220135.1_000006              174                    0.043   \n",
       "pgap_GCF_000220135.1_000007               68                    0.043   \n",
       "pgap_GCF_000220135.1_000012              105                    0.478   \n",
       "...                                      ...                      ...   \n",
       "pgap_GCF_000220135.1_002084              123                    0.130   \n",
       "pgap_GCF_000220135.1_002085              122                    0.130   \n",
       "pgap_GCF_000220135.1_002086               -1                    0.000   \n",
       "pgap_GCF_000220135.1_002087                3                    0.087   \n",
       "pgap_GCF_000220135.1_002088               31                    0.087   \n",
       "\n",
       "                             Upstream Terminator  \n",
       "Protein ID                                        \n",
       "pgap_GCF_000220135.1_000002                    1  \n",
       "pgap_GCF_000220135.1_000005                    0  \n",
       "pgap_GCF_000220135.1_000006                    0  \n",
       "pgap_GCF_000220135.1_000007                    0  \n",
       "pgap_GCF_000220135.1_000012                    0  \n",
       "...                                          ...  \n",
       "pgap_GCF_000220135.1_002084                    0  \n",
       "pgap_GCF_000220135.1_002085                    0  \n",
       "pgap_GCF_000220135.1_002086                    0  \n",
       "pgap_GCF_000220135.1_002087                    0  \n",
       "pgap_GCF_000220135.1_002088                    0  \n",
       "\n",
       "[581 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select The Prediction Target\n",
    "y = ml_data[\"Operonic to IUN\"]\n",
    "display(y)\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"Upstream Terminator\"]\n",
    "X = ml_data[ml_features]\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e969e2f-ac54-4f73-ba19-f0187b14d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.818\n",
      "CV Precision:        0.858\n",
      "CV Recall:           0.891\n",
      "CV F1‐Score:         0.874\n",
      "CV ROC AUC:          0.873\n",
      "CV Log‐Loss:         0.814\n",
      "CV Brier Score:      0.134\n",
      "CV Confusion Matrix:\n",
      " [[107  61]\n",
      " [ 45 368]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (3 features)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=0))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "# print(proba)\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "34d9698d-f2f5-40b1-87fb-7173df223f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4243885956183968, 0.40746972160831296, 0.39508350592756425, 0.3979395481028522, 0.4009805213532528, 0.402730105907013, 0.4020162886063792, 0.4052836976576502, 0.40367391929602403, 0.40773402598152536, 0.40377675555129966, 0.4002488909065671, 0.40080219810214257, 0.4048641281624593, 0.4045808112011883, 0.40506021333205566, 0.4076600616688944, 0.4076351818342148, 0.40864200297135567, 0.40864656190902704, 0.4090915572143798, 0.4076161611076476, 0.4078786338938699, 0.40895751913990763, 0.40886222817367157, 0.40774474368711944, 0.4098753341107698, 0.4085744726669196, 0.40883991779144313, 0.40961744141386786, 0.4107887791798731, 0.40931171829543755, 0.41084126995968506, 0.411604718984102, 0.41152306638669606, 0.4114217577902246, 0.4114225724003892, 0.41182447779641607, 0.4119271053125896, 0.4120482797355156, 0.40890076706163114, 0.40701662519199105, 0.4069775502715639, 0.40686713256536367, 0.40546450300275844, 0.4051508420114813, 0.40519727193203164, 0.4034473768917737, 0.40356039824820755]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find n_estimators plato\n",
    "\n",
    "rf = RandomForestClassifier(warm_start=True, random_state=0) # warm_start=True tells the RandomForestClassifier to reuse the trees it already built (each time only 10 more trees are created)\n",
    "\n",
    "errors = []\n",
    "n_estimators_list = []\n",
    "for n in range(10, 500, 10):\n",
    "    n_estimators_list.append(n)\n",
    "    rf.set_params(n_estimators=n)\n",
    "    rf.fit(train_X, train_y)\n",
    "    proba = rf.predict_proba(val_X)[:,1]\n",
    "    errors.append(log_loss(val_y, proba))\n",
    "print(errors)\n",
    "\n",
    "# Plot n vs. errors to find where it flattens out.\n",
    "plt.plot(n_estimators_list, errors)\n",
    "plt.xlabel(\"Number of Trees (n_estimators)\")\n",
    "plt.ylabel(\"Log-Loss\")\n",
    "plt.title(\"Log-Loss vs. n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0e754de-58e2-4684-aaf4-af69cf5eac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4789391155445717, 0.4395048686890971, 0.4643402835911271, 0.45667867953288244, 0.4453838145180872, 0.4446163122025041, 0.4267734247202573, 0.4231089788537852, 0.4215306586016052, 0.41845910777349504, 0.4147858855065166, 0.4148712967216542, 0.4198652014066747, 0.4202989272159705, 0.42068081832030796, 0.42546228764734595, 0.42348259186007337, 0.42477211307916696, 0.42117125297042607, 0.42274395857047087, 0.4213547530603079, 0.4227009894367505, 0.42235737444486987, 0.42343388818809446, 0.42148736599630215, 0.4200491887328402, 0.4195579257599843, 0.42097767489773047, 0.42196263724110583, 0.4211237503388069, 0.4180128728329363, 0.4190492593946432, 0.4188574937925906, 0.41797213832119495, 0.4179606767702815, 0.41675311495762624, 0.41698865936172735, 0.4153170848206532, 0.41491334612918784, 0.4158290843285335, 0.41569080705808975, 0.4153850283358227, 0.415612184757212, 0.41292868825094253, 0.41169052431490116, 0.41193316110698597, 0.41266236138528445, 0.4113524240259899, 0.4116223091874195]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find n_estimators plato (fresh forests)\n",
    "\n",
    "rf = RandomForestClassifier(warm_start=False, random_state=1)\n",
    "\n",
    "errors = []\n",
    "n_estimators_list = []\n",
    "for n in range(10, 500, 10):\n",
    "    n_estimators_list.append(n)\n",
    "    rf.set_params(n_estimators=n)\n",
    "    rf.fit(train_X, train_y)\n",
    "    proba = rf.predict_proba(val_X)[:,1]\n",
    "    errors.append(log_loss(val_y, proba))\n",
    "print(errors)\n",
    "\n",
    "# Plot n vs. errors to find where it flattens out.\n",
    "plt.plot(n_estimators_list, errors)\n",
    "plt.xlabel(\"Number of Trees (n_estimators)\")\n",
    "plt.ylabel(\"Log-Loss\")\n",
    "plt.title(\"Log-Loss vs. n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035c84e-f662-429c-a222-36a0a7d33852",
   "metadata": {},
   "source": [
    "Once the number of trees in the forest reaches n-estimators=100, the log-loss stops decreasing and reaches a plateau. Therefore, n-estimators=100 is a sufficient number of trees in the forest. Further increasing this parameter will not improve the quality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d938c36-c239-44e2-97e6-1d1e4b0816a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total misclassified across all folds: 101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000237</th>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000272</th>\n",
       "      <td>148</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001081</th>\n",
       "      <td>156</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001391</th>\n",
       "      <td>87</td>\n",
       "      <td>0.565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001274</th>\n",
       "      <td>202</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001164</th>\n",
       "      <td>131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001193</th>\n",
       "      <td>205</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001070</th>\n",
       "      <td>191</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001162</th>\n",
       "      <td>635</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_001733</th>\n",
       "      <td>149</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Distance to IUN  Hamming Distance to IUN  \\\n",
       "Protein ID                                                              \n",
       "pgap_GCF_000220135.1_000237               90                      NaN   \n",
       "pgap_GCF_000220135.1_000272              148                    0.043   \n",
       "pgap_GCF_000220135.1_001081              156                    0.087   \n",
       "pgap_GCF_000220135.1_001391               87                    0.565   \n",
       "pgap_GCF_000220135.1_001274              202                    0.043   \n",
       "...                                      ...                      ...   \n",
       "pgap_GCF_000220135.1_001164              131                    0.000   \n",
       "pgap_GCF_000220135.1_001193              205                    0.087   \n",
       "pgap_GCF_000220135.1_001070              191                    0.043   \n",
       "pgap_GCF_000220135.1_001162              635                    0.261   \n",
       "pgap_GCF_000220135.1_001733              149                    0.000   \n",
       "\n",
       "                             GOntoSim Similarity to IUN  \\\n",
       "Protein ID                                                \n",
       "pgap_GCF_000220135.1_000237                         NaN   \n",
       "pgap_GCF_000220135.1_000272                         NaN   \n",
       "pgap_GCF_000220135.1_001081                         NaN   \n",
       "pgap_GCF_000220135.1_001391                         NaN   \n",
       "pgap_GCF_000220135.1_001274                         NaN   \n",
       "...                                                 ...   \n",
       "pgap_GCF_000220135.1_001164                         NaN   \n",
       "pgap_GCF_000220135.1_001193                       0.378   \n",
       "pgap_GCF_000220135.1_001070                         NaN   \n",
       "pgap_GCF_000220135.1_001162                       0.425   \n",
       "pgap_GCF_000220135.1_001733                         NaN   \n",
       "\n",
       "                             Wang Similarity to IUN  Upstream Terminator  \\\n",
       "Protein ID                                                                 \n",
       "pgap_GCF_000220135.1_000237                     NaN                    0   \n",
       "pgap_GCF_000220135.1_000272                     NaN                    0   \n",
       "pgap_GCF_000220135.1_001081                     NaN                    0   \n",
       "pgap_GCF_000220135.1_001391                     NaN                    0   \n",
       "pgap_GCF_000220135.1_001274                     NaN                    0   \n",
       "...                                             ...                  ...   \n",
       "pgap_GCF_000220135.1_001164                     NaN                    0   \n",
       "pgap_GCF_000220135.1_001193                   0.546                    0   \n",
       "pgap_GCF_000220135.1_001070                     NaN                    1   \n",
       "pgap_GCF_000220135.1_001162                   0.343                    0   \n",
       "pgap_GCF_000220135.1_001733                     NaN                    0   \n",
       "\n",
       "                             y_true  y_pred     proba  \n",
       "Protein ID                                             \n",
       "pgap_GCF_000220135.1_000237       0       1  0.592333  \n",
       "pgap_GCF_000220135.1_000272       0       1  0.910000  \n",
       "pgap_GCF_000220135.1_001081       0       1  0.840000  \n",
       "pgap_GCF_000220135.1_001391       0       1  0.778333  \n",
       "pgap_GCF_000220135.1_001274       0       1  0.982500  \n",
       "...                             ...     ...       ...  \n",
       "pgap_GCF_000220135.1_001164       1       0  0.090000  \n",
       "pgap_GCF_000220135.1_001193       1       0  0.340000  \n",
       "pgap_GCF_000220135.1_001070       1       0  0.320000  \n",
       "pgap_GCF_000220135.1_001162       1       0  0.130000  \n",
       "pgap_GCF_000220135.1_001733       1       0  0.210000  \n",
       "\n",
       "[101 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check rows with fake predictions\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Select The Prediction Target\n",
    "y = ml_data[\"Operonic to IUN\"]\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator\"]\n",
    "X = ml_data[ml_features]\n",
    "# display(X)\n",
    "\n",
    "# Assume X is a DataFrame and y is a Series or array\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=0))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0) # shuffle \n",
    "\n",
    "# To store misclassified rows\n",
    "bad_rows = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y), start=1): # cv.split(X, y) returns a generator that, on each iteration, yields a tuple (train_idx, test_idx); fold is the fold number (1 through n_splits)\n",
    "    # print(fold, (train_idx, test_idx))\n",
    "    # Split\n",
    "    X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Fit\n",
    "    pipeline.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predict proba and hard labels on this fold’s validation set\n",
    "    proba = pipeline.predict_proba(X_te)[:, 1]\n",
    "    y_pred = (proba >= 0.5).astype(int)\n",
    "    \n",
    "    # Find misclassifications in this fold\n",
    "    mask_bad = (y_pred != y_te)\n",
    "    \n",
    "    # Slice out those rows from X_te\n",
    "    df_bad = X_te[mask_bad].copy()\n",
    "    df_bad['y_true']   = y_te[mask_bad]\n",
    "    df_bad['y_pred']   = y_pred[mask_bad]\n",
    "    df_bad['proba']    = proba[mask_bad]\n",
    "    # df_bad['fold']     = fold\n",
    "    \n",
    "    bad_rows.append(df_bad)\n",
    "\n",
    "# Concatenate all bad rows into one DataFrame\n",
    "misclassified = pd.concat(bad_rows)\n",
    "misclassified = misclassified.drop(\"fold\", axis=1).sort_values(by=\"y_true\")\n",
    "\n",
    "# Inspect\n",
    "print(f\"Total misclassified across all folds: {len(misclassified)}\")\n",
    "display(misclassified)\n",
    "misclassified.to_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/ML/misclassified.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673cf86f-5e7f-4d97-85c5-56a3c41742c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters tuning (Setting up a GridSearchCV)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_features': [1, 2, 3, 4, None],\n",
    "    'model__max_depth': [2, 6, 10, None],\n",
    "    'model__min_samples_leaf': [1, 2, 5, 10, 0.05, 0.1],\n",
    "    'model__min_samples_split': [2, 5, 10, 0.05, 0.1, 0.2],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_inner,\n",
    "    # scoring=\"f1\",   # or 'balanced_accuracy' if positives/negatives equally important\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c02c8-9e57-43d0-a300-00da251037c3",
   "metadata": {},
   "source": [
    "Balanced accuracy is (TPR+TNR)/2, the average of sensitivity and specificity.\n",
    "It treats the positive and negative classes exactly equally, rewarding parameter settings that do well on both.\n",
    "\n",
    "Balanced accuracy:\n",
    "Best params: {'model__bootstrap': True, 'model__max_depth': 2, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 0.2}\n",
    "Best CV score: 0.8104629290607062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c1e637-c576-445d-9284-97e4e274fd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000002</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000005</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000006</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000007</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000012</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002084</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002085</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002086</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002087</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002088</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Distance to IUN  Hamming Distance to IUN  \\\n",
       "Protein ID                                                              \n",
       "pgap_GCF_000220135.1_000002              575                    0.043   \n",
       "pgap_GCF_000220135.1_000005              134                    0.043   \n",
       "pgap_GCF_000220135.1_000006              174                    0.043   \n",
       "pgap_GCF_000220135.1_000007               68                    0.043   \n",
       "pgap_GCF_000220135.1_000012              105                    0.478   \n",
       "...                                      ...                      ...   \n",
       "pgap_GCF_000220135.1_002084              123                    0.130   \n",
       "pgap_GCF_000220135.1_002085              122                    0.130   \n",
       "pgap_GCF_000220135.1_002086               -1                    0.000   \n",
       "pgap_GCF_000220135.1_002087                3                    0.087   \n",
       "pgap_GCF_000220135.1_002088               31                    0.087   \n",
       "\n",
       "                             GOntoSim Similarity to IUN  \\\n",
       "Protein ID                                                \n",
       "pgap_GCF_000220135.1_000002                       0.738   \n",
       "pgap_GCF_000220135.1_000005                         NaN   \n",
       "pgap_GCF_000220135.1_000006                       0.845   \n",
       "pgap_GCF_000220135.1_000007                         NaN   \n",
       "pgap_GCF_000220135.1_000012                         NaN   \n",
       "...                                                 ...   \n",
       "pgap_GCF_000220135.1_002084                         NaN   \n",
       "pgap_GCF_000220135.1_002085                         NaN   \n",
       "pgap_GCF_000220135.1_002086                         NaN   \n",
       "pgap_GCF_000220135.1_002087                         NaN   \n",
       "pgap_GCF_000220135.1_002088                       0.364   \n",
       "\n",
       "                             Wang Similarity to IUN  Upstream Terminator  \n",
       "Protein ID                                                                \n",
       "pgap_GCF_000220135.1_000002                   0.735                    1  \n",
       "pgap_GCF_000220135.1_000005                     NaN                    0  \n",
       "pgap_GCF_000220135.1_000006                   0.901                    0  \n",
       "pgap_GCF_000220135.1_000007                     NaN                    0  \n",
       "pgap_GCF_000220135.1_000012                     NaN                    0  \n",
       "...                                             ...                  ...  \n",
       "pgap_GCF_000220135.1_002084                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002085                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002086                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002087                     NaN                    0  \n",
       "pgap_GCF_000220135.1_002088                   0.514                    0  \n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select The Prediction Target\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ml_data = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/tu_input_for_ml_prom.tsv\", sep=\"\\t\").set_index(\"Protein ID\")\n",
    "\n",
    "y = ml_data[\"Operonic to IUN\"]\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator\"]\n",
    "X = ml_data[ml_features]\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d97385-dda2-4c4a-a170-eb58edb34696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58568727 0.36660832 0.67140669 0.85902084 0.65720849 0.74976607\n",
      " 0.33958769 0.35528253 0.97658703 0.85660065 0.97658703 0.97658703\n",
      " 0.97658703 0.97658703 0.97658703 0.97658703 0.28114809 0.24469438\n",
      " 0.84090836 0.28947925 0.27294584 0.28417289 0.26992103 0.63512083\n",
      " 0.39848895 0.96219268 0.27632238 0.23578438 0.59991344 0.28760203\n",
      " 0.97658703 0.67140669 0.56696941 0.58242632 0.36660832 0.86519015\n",
      " 0.67154442 0.6963161  0.27632238 0.97658703 0.46268739 0.94921469\n",
      " 0.28619526 0.36660832 0.62564122 0.29502252 0.20375983 0.79285632\n",
      " 0.95900447 0.93173481 0.46484603 0.97658703 0.29199771 0.96606641\n",
      " 0.61598785 0.63353298 0.31918674 0.62064147 0.97658703 0.67154442\n",
      " 0.97658703 0.28417289 0.97658703 0.36660832 0.97658703 0.97658703\n",
      " 0.93485405 0.97658703 0.22778371 0.23346732 0.35081475 0.97658703\n",
      " 0.97658703 0.97658703 0.35538126 0.97658703 0.35866526 0.27294584\n",
      " 0.3271298  0.97658703 0.97658703 0.97658703 0.35866526 0.93485405\n",
      " 0.24682573 0.80855389 0.30804047 0.81536422 0.94972154 0.97658703\n",
      " 0.86519015 0.97658703 0.97658703 0.97658703 0.97658703 0.31565721\n",
      " 0.38658134 0.35866526 0.39185066 0.94921469 0.53067921 0.32820792\n",
      " 0.12437784 0.38658134 0.97658703 0.97658703 0.44957549 0.29502252\n",
      " 0.77604523 0.30804047 0.51686091 0.61308281 0.44604776 0.97658703\n",
      " 0.79730582 0.79285632 0.79285632 0.33043556 0.95900447 0.96219268\n",
      " 0.94921469 0.93485405 0.97658703 0.38696627 0.44499657 0.36660832\n",
      " 0.67080365 0.36660832 0.97658703 0.97658703 0.24866353 0.36660832\n",
      " 0.34090683 0.78197754 0.98226135 0.42313336 0.14362112 0.51605723\n",
      " 0.79228458 0.9832783  0.9832783  0.67080365 0.73854312 0.93201094\n",
      " 0.9832783  0.9832783  0.30804047 0.62737263 0.9832783  0.69211617\n",
      " 0.51185361 0.8390839  0.20299807 0.9832783  0.9832783  0.53100119\n",
      " 0.96151822 0.43005261 0.9832783  0.9832783  0.98226135 0.16989297\n",
      " 0.54402399 0.65680484 0.76113015 0.381805   0.9832783  0.9832783\n",
      " 0.98226135 0.9832783  0.9832783  0.98226135 0.24971472 0.24866353\n",
      " 0.93201094 0.54308402 0.30804047 0.9604335  0.9832783  0.93764184\n",
      " 0.98226135 0.9832783  0.9832783  0.75479029 0.9832783  0.3675345\n",
      " 0.9832783  0.9832783  0.9832783  0.50437352 0.9832783  0.9832783\n",
      " 0.9832783  0.9832783  0.9832783  0.47198431 0.98226135 0.9832783\n",
      " 0.9832783  0.51086703 0.74238662 0.46106708 0.95895158 0.71422208\n",
      " 0.67080365 0.23586443 0.98226135 0.9832783  0.9832783  0.9832783\n",
      " 0.9832783  0.34090683 0.50437352 0.51085413 0.14040237 0.53444925\n",
      " 0.4918211  0.38211763 0.9832783  0.9832783  0.39386342 0.59175497\n",
      " 0.25364085 0.97430469 0.45742652 0.9832783  0.48331414 0.78981048\n",
      " 0.85672435 0.92737069 0.9832783  0.9832783  0.91689871 0.43505274\n",
      " 0.63545907 0.98226135 0.63177913 0.2941467  0.9832783  0.51086703\n",
      " 0.44933962 0.43209647 0.66787913 0.9832783  0.8166452  0.9832783\n",
      " 0.76113015 0.97430469 0.97430469 0.97430469 0.50278086 0.69768971\n",
      " 0.4612886  0.4612886  0.97430469 0.97430469 0.4612886  0.96476522\n",
      " 0.97430469 0.4571034  0.71713274 0.97430469 0.97430469 0.97430469\n",
      " 0.97430469 0.97430469 0.97430469 0.97430469 0.97430469 0.21079052\n",
      " 0.34386491 0.51770317 0.4571034  0.85672435 0.69846236 0.53444925\n",
      " 0.64591763 0.85672435 0.25782606 0.42602173 0.96893857 0.3019539\n",
      " 0.97430469 0.97430469 0.97430469 0.50278086 0.97430469 0.97430469\n",
      " 0.97430469 0.38211763 0.97132533 0.48542109 0.34144725 0.97430469\n",
      " 0.4571034  0.38211763 0.50278086 0.97132533 0.85672435 0.97430469\n",
      " 0.69768971 0.87641785 0.97430469 0.64591763 0.64591763 0.64591763\n",
      " 0.64591763 0.27628269 0.91748398 0.37319695 0.97430469 0.97430469\n",
      " 0.97430469 0.90758007 0.96476522 0.86769368 0.97430469 0.97430469\n",
      " 0.97430469 0.97430469 0.39386342 0.82885967 0.4960063  0.97430469\n",
      " 0.97430469 0.70865904 0.75789146 0.80760909 0.86161088 0.97430469\n",
      " 0.97430469 0.97430469 0.97430469 0.97430469 0.61463135 0.97430469\n",
      " 0.86161088 0.34144725 0.97430469 0.3854872  0.3976581  0.2899615\n",
      " 0.34386491 0.97430469 0.30093083 0.97430469 0.47510986 0.97820077\n",
      " 0.97550847 0.97377678 0.55076701 0.45746011 0.97820077 0.97820077\n",
      " 0.97820077 0.97820077 0.97820077 0.4396676  0.97820077 0.2036057\n",
      " 0.62095692 0.45566114 0.88234172 0.97820077 0.97820077 0.97129815\n",
      " 0.38211763 0.88234172 0.22594506 0.97820077 0.87474435 0.41852495\n",
      " 0.97820077 0.44842704 0.95503859 0.41363828 0.74026708 0.46482748\n",
      " 0.97550847 0.97820077 0.4396676  0.25462039 0.56292875 0.87742163\n",
      " 0.97820077 0.91885009 0.44725708 0.57998169 0.45746011 0.69435598\n",
      " 0.41852495 0.41373773 0.46635042 0.71618739 0.69435598 0.93379002\n",
      " 0.97820077 0.97820077 0.97820077 0.93104898 0.85890279 0.29763012\n",
      " 0.31771078 0.97550847 0.97820077 0.35913168 0.37193043 0.84963814\n",
      " 0.40986485 0.97820077 0.97129815 0.28757153 0.41852495 0.97129815\n",
      " 0.69971214 0.36674891 0.97820077 0.74393819 0.97820077 0.97820077\n",
      " 0.97129815 0.97550847 0.97129815 0.97820077 0.97820077 0.97820077\n",
      " 0.97820077 0.97820077 0.97377678 0.46635042 0.97820077 0.97820077\n",
      " 0.97820077 0.97820077 0.88688219 0.97820077 0.79384174 0.12830654\n",
      " 0.4356112  0.8398704  0.97820077 0.97820077 0.97820077 0.47510986\n",
      " 0.69435598 0.97820077 0.6848494  0.55439768 0.75372235 0.97820077\n",
      " 0.82064502 0.97820077 0.97820077 0.87853181 0.96861046 0.97820077\n",
      " 0.95114467 0.97915668 0.98113782 0.85344806 0.27698732 0.37286692\n",
      " 0.47510986 0.28197091 0.27415905 0.4520443  0.97809739 0.38669995\n",
      " 0.38674778 0.8598229  0.48932169 0.15132966 0.45332534 0.91181205\n",
      " 0.67489747 0.98113782 0.96164277 0.55013864 0.55013864 0.32891288\n",
      " 0.46392036 0.58028924 0.48493738 0.52973647 0.98113782 0.98113782\n",
      " 0.4712189  0.43806165 0.98113782 0.38388103 0.15132966 0.48932169\n",
      " 0.50584914 0.49712171 0.28197091 0.53528108 0.75258708 0.81824314\n",
      " 0.63371064 0.5576011  0.98113782 0.50651302 0.49712171 0.25431378\n",
      " 0.98113782 0.98113782 0.98113782 0.98113782 0.98113782 0.76280165\n",
      " 0.98113782 0.98113782 0.98113782 0.75839776 0.98113782 0.98113782\n",
      " 0.98113782 0.98113782 0.98113782 0.98113782 0.97915668 0.98113782\n",
      " 0.98113782 0.98113782 0.98113782 0.18662378 0.51904159 0.88380004\n",
      " 0.91379318 0.12344368 0.49712171 0.98113782 0.28340343 0.6200514\n",
      " 0.12344368 0.47475843 0.49712171 0.60377301 0.91181205 0.98113782\n",
      " 0.98113782 0.91181205 0.30795592 0.98113782 0.51888304 0.49712171\n",
      " 0.75839776 0.98113782 0.72719271 0.95796625 0.98113782 0.95796625\n",
      " 0.97915668 0.98113782 0.40177459 0.98113782 0.92925009 0.26466141\n",
      " 0.46790575 0.26665643 0.4712189  0.98113782 0.24077042 0.28146376\n",
      " 0.53795431 0.93952764 0.64310564 0.13306384 0.75839776 0.97915668\n",
      " 0.24667679 0.79257736 0.98113782 0.46790575 0.98113782 0.28340343\n",
      " 0.53765466 0.53765466 0.98113782 0.98113782 0.98113782]\n",
      "CV Accuracy:         0.821\n",
      "CV Precision:        0.883\n",
      "CV Recall:           0.862\n",
      "CV F1‐Score:         0.873\n",
      "CV ROC AUC:          0.894\n",
      "CV Log‐Loss:         0.364\n",
      "CV Brier Score:      0.120\n",
      "CV Confusion Matrix:\n",
      " [[121  47]\n",
      " [ 57 356]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (5 features) and tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=2, max_features=None, min_samples_leaf=1, min_samples_split=0.2, random_state=0))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235b28f-5ff6-4392-921d-b4e90dfd5cc3",
   "metadata": {},
   "source": [
    "Added data from promoters predicted using G4PromFinder to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daee2dff-97ea-47ca-be58-f0244d870160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protein ID\n",
       "pgap_GCF_000220135.1_000002    0\n",
       "pgap_GCF_000220135.1_000005    0\n",
       "pgap_GCF_000220135.1_000006    1\n",
       "pgap_GCF_000220135.1_000007    1\n",
       "pgap_GCF_000220135.1_000012    0\n",
       "                              ..\n",
       "pgap_GCF_000220135.1_002084    1\n",
       "pgap_GCF_000220135.1_002085    1\n",
       "pgap_GCF_000220135.1_002086    1\n",
       "pgap_GCF_000220135.1_002087    1\n",
       "pgap_GCF_000220135.1_002088    1\n",
       "Name: Operonic to IUN, Length: 581, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator</th>\n",
       "      <th>Upstream Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protein ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000002</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000005</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000006</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000007</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_000012</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002084</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002085</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002086</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002087</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgap_GCF_000220135.1_002088</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Distance to IUN  Hamming Distance to IUN  \\\n",
       "Protein ID                                                              \n",
       "pgap_GCF_000220135.1_000002              575                    0.043   \n",
       "pgap_GCF_000220135.1_000005              134                    0.043   \n",
       "pgap_GCF_000220135.1_000006              174                    0.043   \n",
       "pgap_GCF_000220135.1_000007               68                    0.043   \n",
       "pgap_GCF_000220135.1_000012              105                    0.478   \n",
       "...                                      ...                      ...   \n",
       "pgap_GCF_000220135.1_002084              123                    0.130   \n",
       "pgap_GCF_000220135.1_002085              122                    0.130   \n",
       "pgap_GCF_000220135.1_002086               -1                    0.000   \n",
       "pgap_GCF_000220135.1_002087                3                    0.087   \n",
       "pgap_GCF_000220135.1_002088               31                    0.087   \n",
       "\n",
       "                             GOntoSim Similarity to IUN  \\\n",
       "Protein ID                                                \n",
       "pgap_GCF_000220135.1_000002                       0.738   \n",
       "pgap_GCF_000220135.1_000005                         NaN   \n",
       "pgap_GCF_000220135.1_000006                       0.845   \n",
       "pgap_GCF_000220135.1_000007                         NaN   \n",
       "pgap_GCF_000220135.1_000012                         NaN   \n",
       "...                                                 ...   \n",
       "pgap_GCF_000220135.1_002084                         NaN   \n",
       "pgap_GCF_000220135.1_002085                         NaN   \n",
       "pgap_GCF_000220135.1_002086                         NaN   \n",
       "pgap_GCF_000220135.1_002087                         NaN   \n",
       "pgap_GCF_000220135.1_002088                       0.364   \n",
       "\n",
       "                             Wang Similarity to IUN  Upstream Terminator  \\\n",
       "Protein ID                                                                 \n",
       "pgap_GCF_000220135.1_000002                   0.735                    1   \n",
       "pgap_GCF_000220135.1_000005                     NaN                    0   \n",
       "pgap_GCF_000220135.1_000006                   0.901                    0   \n",
       "pgap_GCF_000220135.1_000007                     NaN                    0   \n",
       "pgap_GCF_000220135.1_000012                     NaN                    0   \n",
       "...                                             ...                  ...   \n",
       "pgap_GCF_000220135.1_002084                     NaN                    0   \n",
       "pgap_GCF_000220135.1_002085                     NaN                    0   \n",
       "pgap_GCF_000220135.1_002086                     NaN                    0   \n",
       "pgap_GCF_000220135.1_002087                     NaN                    0   \n",
       "pgap_GCF_000220135.1_002088                   0.514                    0   \n",
       "\n",
       "                             Upstream Promoter  \n",
       "Protein ID                                      \n",
       "pgap_GCF_000220135.1_000002                  0  \n",
       "pgap_GCF_000220135.1_000005                  0  \n",
       "pgap_GCF_000220135.1_000006                  0  \n",
       "pgap_GCF_000220135.1_000007                  0  \n",
       "pgap_GCF_000220135.1_000012                  1  \n",
       "...                                        ...  \n",
       "pgap_GCF_000220135.1_002084                  0  \n",
       "pgap_GCF_000220135.1_002085                  0  \n",
       "pgap_GCF_000220135.1_002086                  0  \n",
       "pgap_GCF_000220135.1_002087                  0  \n",
       "pgap_GCF_000220135.1_002088                  0  \n",
       "\n",
       "[581 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ml_data_prom = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/tu_input_for_ml_prom.tsv\", sep=\"\\t\").set_index(\"Protein ID\")\n",
    "\n",
    "# Select The Prediction Target\n",
    "y = ml_data_prom[\"Operonic to IUN\"]\n",
    "# display(y)\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator\", \"Upstream Promoter\"]\n",
    "X = ml_data_prom[ml_features]\n",
    "# display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a9ceab-c574-4e96-a83b-1bf2c419fb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    581.000000\n",
       "mean       0.044750\n",
       "std        0.206934\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000\n",
       "Name: Upstream Promoter, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Upstream Promoter Feature\n",
    "\n",
    "X[\"Upstream Promoter\"].describe()\n",
    "# X.corr()[\"Upstream Promoter\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a31910c-c8c0-4132-af5e-a86c841fbace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57272452 0.37363217 0.65616264 0.82885175 0.64952638 0.70766271\n",
      " 0.35204175 0.36456483 0.97975834 0.82585496 0.97975834 0.97975834\n",
      " 0.97975834 0.97975834 0.97975834 0.97975834 0.2936498  0.28561603\n",
      " 0.81842874 0.27831613 0.30737069 0.30271713 0.28112671 0.58593385\n",
      " 0.44860207 0.97405564 0.31860423 0.24666148 0.58463823 0.32359757\n",
      " 0.97975834 0.65616264 0.56732821 0.52012019 0.37363217 0.86822779\n",
      " 0.64868569 0.69056805 0.31082645 0.97975834 0.43472277 0.96675865\n",
      " 0.26579304 0.37363217 0.57296453 0.30689522 0.19487801 0.79045063\n",
      " 0.96675865 0.94450339 0.50323985 0.97975834 0.30876401 0.97405564\n",
      " 0.60685069 0.58154317 0.33935442 0.55996387 0.97975834 0.6456889\n",
      " 0.97975834 0.31989378 0.97975834 0.37363217 0.97975834 0.97746667\n",
      " 0.94022931 0.97975834 0.21349458 0.2559163  0.36456483 0.97975834\n",
      " 0.97975834 0.97975834 0.36110908 0.97975834 0.37363217 0.29019405\n",
      " 0.33935442 0.97746667 0.97975834 0.97975834 0.37363217 0.94022931\n",
      " 0.28687259 0.80929145 0.32959743 0.83155354 0.94246426 0.97975834\n",
      " 0.86758263 0.97975834 0.97975834 0.97975834 0.97975834 0.3252918\n",
      " 0.37659077 0.39080881 0.44241658 0.96446698 0.54759697 0.37567963\n",
      " 0.1411326  0.37659077 0.97975834 0.97975834 0.47554397 0.31783134\n",
      " 0.77368961 0.33363553 0.52546096 0.60712675 0.45252569 0.97975834\n",
      " 0.77264784 0.7927423  0.7927423  0.34328786 0.96675865 0.97405564\n",
      " 0.96675865 0.94022931 0.97975834 0.40394856 0.4890999  0.37363217\n",
      " 0.66916161 0.37363217 0.97975834 0.97975834 0.29326326 0.37363217\n",
      " 0.38356723 0.76943157 0.98098618 0.42042406 0.1653981  0.52058359\n",
      " 0.77368961 0.98205001 0.98205001 0.66916161 0.73232559 0.93061669\n",
      " 0.98205001 0.98205001 0.33801053 0.57493749 0.98205001 0.66916161\n",
      " 0.50342703 0.84909852 0.18349275 0.98205001 0.98205001 0.53705875\n",
      " 0.96390002 0.46858664 0.98205001 0.98205001 0.98098618 0.17679513\n",
      " 0.56917294 0.65518691 0.76943157 0.37659077 0.98205001 0.98205001\n",
      " 0.98098618 0.98205001 0.98205001 0.98098618 0.27896667 0.29763826\n",
      " 0.93481842 0.60488854 0.32959743 0.95428346 0.98205001 0.94349522\n",
      " 0.97820369 0.98205001 0.98205001 0.75455699 0.98205001 0.39519192\n",
      " 0.98205001 0.98205001 0.98205001 0.53713453 0.98205001 0.98205001\n",
      " 0.98205001 0.98205001 0.98205001 0.47677405 0.98098618 0.98205001\n",
      " 0.98205001 0.53713453 0.73704106 0.46422615 0.96190002 0.70726092\n",
      " 0.66916161 0.23342445 0.98098618 0.98205001 0.98205001 0.98205001\n",
      " 0.98205001 0.37490275 0.52543406 0.50775471 0.12198095 0.52467512\n",
      " 0.46204684 0.42258794 0.98205001 0.98205001 0.41025341 0.5428169\n",
      " 0.23915635 0.97124809 0.43327914 0.98205001 0.48595023 0.78055892\n",
      " 0.87256063 0.92989836 0.98205001 0.98205001 0.92221884 0.40430736\n",
      " 0.60690887 0.98098618 0.58234118 0.27996849 0.98205001 0.53309643\n",
      " 0.43355287 0.4166283  0.64288862 0.98205001 0.82897244 0.98205001\n",
      " 0.76943157 0.97124809 0.97124809 0.97124809 0.48640961 0.73255211\n",
      " 0.46931956 0.46931956 0.97124809 0.97124809 0.46931956 0.97124809\n",
      " 0.97124809 0.45105666 0.77437505 0.97124809 0.97124809 0.97124809\n",
      " 0.97124809 0.97124809 0.97124809 0.97124809 0.97124809 0.20887409\n",
      " 0.34752779 0.55092161 0.45105666 0.87256063 0.72020641 0.52467512\n",
      " 0.63802548 0.87256063 0.24894995 0.39177394 0.96796461 0.2836875\n",
      " 0.97124809 0.97124809 0.97124809 0.48640961 0.97124809 0.97124809\n",
      " 0.97124809 0.42258794 0.96844306 0.47889931 0.29568157 0.97124809\n",
      " 0.45952597 0.42258794 0.48640961 0.96583446 0.87256063 0.97124809\n",
      " 0.73255211 0.88976495 0.97124809 0.63802548 0.63802548 0.63802548\n",
      " 0.63802548 0.30430881 0.9014337  0.35547136 0.97124809 0.97124809\n",
      " 0.97124809 0.93657596 0.97124809 0.87256063 0.97124809 0.97124809\n",
      " 0.97124809 0.97124809 0.41025341 0.83578768 0.48640961 0.97124809\n",
      " 0.97124809 0.73255211 0.80047242 0.81715885 0.88976495 0.97124809\n",
      " 0.97124809 0.97124809 0.97124809 0.97124809 0.62930787 0.97124809\n",
      " 0.88976495 0.30219727 0.97124809 0.37468389 0.36930534 0.26170559\n",
      " 0.34235057 0.97124809 0.25560572 0.97124809 0.47611671 0.97716296\n",
      " 0.97716296 0.97291137 0.53570299 0.46497522 0.97716296 0.97716296\n",
      " 0.97716296 0.97716296 0.97716296 0.43814432 0.97716296 0.16286422\n",
      " 0.66177591 0.46895457 0.86485253 0.97716296 0.97716296 0.96474329\n",
      " 0.42258794 0.87082509 0.23323686 0.97716296 0.87653046 0.41810492\n",
      " 0.97716296 0.43814432 0.96216497 0.44686768 0.75124563 0.51482896\n",
      " 0.97716296 0.97716296 0.43814432 0.22099372 0.62695294 0.85372715\n",
      " 0.97716296 0.94523358 0.44665167 0.55853199 0.46497522 0.74946837\n",
      " 0.41810492 0.41810492 0.47611671 0.72764174 0.74946837 0.92186717\n",
      " 0.97716296 0.97716296 0.97716296 0.94523358 0.87309834 0.27000028\n",
      " 0.2734289  0.97716296 0.97716296 0.37849012 0.34266907 0.84976872\n",
      " 0.40626353 0.97716296 0.96474329 0.32290264 0.41810492 0.96474329\n",
      " 0.73882596 0.37479277 0.97435344 0.77962829 0.97716296 0.97716296\n",
      " 0.96474329 0.97435344 0.96193377 0.97716296 0.97716296 0.97716296\n",
      " 0.97716296 0.97716296 0.97291137 0.47611671 0.97716296 0.97716296\n",
      " 0.97435344 0.97716296 0.87653046 0.97716296 0.80419885 0.12607849\n",
      " 0.43814432 0.84576499 0.97716296 0.97435344 0.97716296 0.47611671\n",
      " 0.75372562 0.97716296 0.74946837 0.53587395 0.7661431  0.97716296\n",
      " 0.81283247 0.97716296 0.97716296 0.85689037 0.96238854 0.97716296\n",
      " 0.95876459 0.98078859 0.98078859 0.85372715 0.23751044 0.39476155\n",
      " 0.47611671 0.26130185 0.25594919 0.44665167 0.97869573 0.38863987\n",
      " 0.38331601 0.85372715 0.48652468 0.14673007 0.43715422 0.89521666\n",
      " 0.63654544 0.98078859 0.97313412 0.55916574 0.55916574 0.37123521\n",
      " 0.44142401 0.59947937 0.46551553 0.53840581 0.98078859 0.98078859\n",
      " 0.44558657 0.43762039 0.98078859 0.41644495 0.14673007 0.48483096\n",
      " 0.49876018 0.48627546 0.26519204 0.58466579 0.73281021 0.8236458\n",
      " 0.65993698 0.56568515 0.98078859 0.49876018 0.48627546 0.23849757\n",
      " 0.98078859 0.98078859 0.98078859 0.98078859 0.98078859 0.73489425\n",
      " 0.98078859 0.98078859 0.98078859 0.73281021 0.98078859 0.98078859\n",
      " 0.98078859 0.98078859 0.98078859 0.98078859 0.98078859 0.98078859\n",
      " 0.98078859 0.98078859 0.98078859 0.19990369 0.52476899 0.86882081\n",
      " 0.89521666 0.13641051 0.4821129  0.98078859 0.2532159  0.64676818\n",
      " 0.13641051 0.50128319 0.48627546 0.67119018 0.89521666 0.98078859\n",
      " 0.97812906 0.89521666 0.33054632 0.98078859 0.5479937  0.48627546\n",
      " 0.73281021 0.97812906 0.69588841 0.97313412 0.98078859 0.97313412\n",
      " 0.98078859 0.98078859 0.4248773  0.98078859 0.92823244 0.24486619\n",
      " 0.46338237 0.23097608 0.44558657 0.98078859 0.23454663 0.2612411\n",
      " 0.53840581 0.9494282  0.73521742 0.13641051 0.72885927 0.98078859\n",
      " 0.20812823 0.80999786 0.98078859 0.46338237 0.98078859 0.2532159\n",
      " 0.5439302  0.55916574 0.98078859 0.98078859 0.98078859]\n",
      "CV Accuracy:         0.818\n",
      "CV Precision:        0.883\n",
      "CV Recall:           0.857\n",
      "CV F1‐Score:         0.870\n",
      "CV ROC AUC:          0.893\n",
      "CV Log‐Loss:         0.365\n",
      "CV Brier Score:      0.121\n",
      "CV Confusion Matrix:\n",
      " [[121  47]\n",
      " [ 59 354]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (6 features) and tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=2, max_features=None, min_samples_leaf=1, min_samples_split=0.2, random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "501bb649-7bb2-4ee8-9e76-3828707f68a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator Inter</th>\n",
       "      <th>Upstream Promoter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distance to IUN  Hamming Distance to IUN  GOntoSim Similarity to IUN  \\\n",
       "0                575                    0.043                       0.738   \n",
       "1                134                    0.043                         NaN   \n",
       "2                174                    0.043                       0.845   \n",
       "3                 68                    0.043                         NaN   \n",
       "4                105                    0.478                         NaN   \n",
       "..               ...                      ...                         ...   \n",
       "576              123                    0.130                         NaN   \n",
       "577              122                    0.130                         NaN   \n",
       "578               -1                    0.000                         NaN   \n",
       "579                3                    0.087                         NaN   \n",
       "580               31                    0.087                       0.364   \n",
       "\n",
       "     Wang Similarity to IUN  Upstream Terminator Inter  Upstream Promoter  \n",
       "0                     0.735                          1                  0  \n",
       "1                       NaN                          0                  0  \n",
       "2                     0.901                          0                  0  \n",
       "3                       NaN                          0                  0  \n",
       "4                       NaN                          0                  1  \n",
       "..                      ...                        ...                ...  \n",
       "576                     NaN                          0                  0  \n",
       "577                     NaN                          0                  0  \n",
       "578                     NaN                          0                  0  \n",
       "579                     NaN                          0                  0  \n",
       "580                   0.514                          0                  0  \n",
       "\n",
       "[581 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ml_data_term = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/tu_input_for_ml_term_inter.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Select The Prediction Target\n",
    "y = ml_data_term[\"Operonic to IUN\"]\n",
    "# display(y)\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator Inter\", \"Upstream Promoter\"]\n",
    "X_6f = ml_data_term[ml_features]\n",
    "# display(X_6f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c77718f8-6497-4e81-99ff-e89fb32c4ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Upstream Terminator Inter     1.000000\n",
       "Distance to IUN               0.378576\n",
       "Hamming Distance to IUN       0.058555\n",
       "Upstream Promoter            -0.009537\n",
       "GOntoSim Similarity to IUN   -0.142517\n",
       "Wang Similarity to IUN       -0.160698\n",
       "Name: Upstream Terminator Inter, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Upstream Intergenic Terminator Feature\n",
    "\n",
    "# X[\"Upstream Terminator Inter\"].describe()\n",
    "X.corr()[\"Upstream Terminator Inter\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba1d094-b06e-4ef6-9699-fa9add8ec03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.816\n",
      "CV Precision:        0.882\n",
      "CV Recall:           0.855\n",
      "CV F1‐Score:         0.868\n",
      "CV ROC AUC:          0.895\n",
      "CV Log‐Loss:         0.364\n",
      "CV Brier Score:      0.120\n",
      "CV Confusion Matrix:\n",
      " [[121  47]\n",
      " [ 60 353]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (6 features, including Upstream Intergenic Terminator) w/o tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=2, max_features=None, min_samples_leaf=1, min_samples_split=0.2, random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a27c72-65f8-4502-8b0d-0f375e9ad350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__bootstrap': True, 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10}\n",
      "Best CV score: 0.8207196596481138\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning (Setting up a GridSearchCV)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_features': [1, 2, 3, 4, None],\n",
    "    'model__max_depth': [2, 6, 10, None],\n",
    "    'model__min_samples_leaf': [1, 2, 5, 10, 0.05, 0.1],\n",
    "    'model__min_samples_split': [2, 5, 10, 0.05, 0.1, 0.2],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_inner,\n",
    "    # scoring=\"f1\",   # or 'balanced_accuracy' if positives/negatives equally important\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5af7ad50-e497-4064-8c83-801a4fb78d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.831\n",
      "CV Precision:        0.876\n",
      "CV Recall:           0.889\n",
      "CV F1‐Score:         0.882\n",
      "CV ROC AUC:          0.910\n",
      "CV Log‐Loss:         0.399\n",
      "CV Brier Score:      0.110\n",
      "CV Confusion Matrix:\n",
      " [[116  52]\n",
      " [ 46 367]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (6 features, including Upstream Intergenic Terminator) and tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10, random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X_6f, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393b16fd-8712-4e3f-84af-7606561ed544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator Inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distance to IUN  Hamming Distance to IUN  GOntoSim Similarity to IUN  \\\n",
       "0                575                    0.043                       0.738   \n",
       "1                134                    0.043                         NaN   \n",
       "2                174                    0.043                       0.845   \n",
       "3                 68                    0.043                         NaN   \n",
       "4                105                    0.478                         NaN   \n",
       "..               ...                      ...                         ...   \n",
       "576              123                    0.130                         NaN   \n",
       "577              122                    0.130                         NaN   \n",
       "578               -1                    0.000                         NaN   \n",
       "579                3                    0.087                         NaN   \n",
       "580               31                    0.087                       0.364   \n",
       "\n",
       "     Wang Similarity to IUN  Upstream Terminator Inter  \n",
       "0                     0.735                          1  \n",
       "1                       NaN                          0  \n",
       "2                     0.901                          0  \n",
       "3                       NaN                          0  \n",
       "4                       NaN                          0  \n",
       "..                      ...                        ...  \n",
       "576                     NaN                          0  \n",
       "577                     NaN                          0  \n",
       "578                     NaN                          0  \n",
       "579                     NaN                          0  \n",
       "580                   0.514                          0  \n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ml_data_term = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/tu_input_for_ml_term_inter.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Select The Prediction Target\n",
    "y = ml_data_term[\"Operonic to IUN\"]\n",
    "# display(y)\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator Inter\"]\n",
    "X = ml_data_term[ml_features]\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2278efc4-d330-4423-9218-aea05c5f6677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__bootstrap': True, 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10}\n",
      "Best CV score: 0.8194257138112906\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning (Setting up a GridSearchCV)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_features': [1, 2, 3, 4, None],\n",
    "    'model__max_depth': [2, 6, 10, None],\n",
    "    'model__min_samples_leaf': [1, 2, 5, 10, 0.05, 0.1],\n",
    "    'model__min_samples_split': [2, 5, 10, 0.05, 0.1, 0.2],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_inner,\n",
    "    # scoring=\"f1\",   # or 'balanced_accuracy' if positives/negatives equally important\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c618f288-dac9-42e0-8797-9c73da9d291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.835\n",
      "CV Precision:        0.878\n",
      "CV Recall:           0.891\n",
      "CV F1‐Score:         0.885\n",
      "CV ROC AUC:          0.911\n",
      "CV Log‐Loss:         0.398\n",
      "CV Brier Score:      0.110\n",
      "CV Confusion Matrix:\n",
      " [[117  51]\n",
      " [ 45 368]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (5 features, no Upstream Promoter) and tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10, random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fae851-3d6d-4393-8f9a-4a82440f156e",
   "metadata": {},
   "source": [
    "Thus, the best results are demonstrated by the model without predicted promoters and with updated terminators. It is necessary to examine the correlation for other features and exclude them from the model if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b20715bb-c788-4f55-9a5e-60b637d51b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Distance to IUN       1.000000\n",
       "Distance to IUN               0.123332\n",
       "Upstream Terminator Inter     0.058555\n",
       "GOntoSim Similarity to IUN   -0.201432\n",
       "Operonic to IUN              -0.204717\n",
       "Wang Similarity to IUN       -0.209265\n",
       "Name: Hamming Distance to IUN, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Upstream Intergenic Terminator Feature\n",
    "\n",
    "ml_features = [\"Operonic to IUN\", \"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator Inter\"]\n",
    "data = ml_data_term[ml_features]\n",
    "# display(data)\n",
    "\n",
    "# data[\"Hamming Distance to IUN\"].describe()\n",
    "data.corr()[\"Hamming Distance to IUN\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228feca-1da1-453e-9347-edf1d19a8513",
   "metadata": {},
   "source": [
    "Remove GOntoSim Similarity to IUN/ Wang Similarity to IUN, as they correlate significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccf5e065-19e3-4606-9e5b-06b925d269b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>GOntoSim Similarity to IUN</th>\n",
       "      <th>Upstream Terminator Inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distance to IUN  Hamming Distance to IUN  GOntoSim Similarity to IUN  \\\n",
       "0                575                    0.043                       0.738   \n",
       "1                134                    0.043                         NaN   \n",
       "2                174                    0.043                       0.845   \n",
       "3                 68                    0.043                         NaN   \n",
       "4                105                    0.478                         NaN   \n",
       "..               ...                      ...                         ...   \n",
       "576              123                    0.130                         NaN   \n",
       "577              122                    0.130                         NaN   \n",
       "578               -1                    0.000                         NaN   \n",
       "579                3                    0.087                         NaN   \n",
       "580               31                    0.087                       0.364   \n",
       "\n",
       "     Upstream Terminator Inter  \n",
       "0                            1  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "..                         ...  \n",
       "576                          0  \n",
       "577                          0  \n",
       "578                          0  \n",
       "579                          0  \n",
       "580                          0  \n",
       "\n",
       "[581 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ml_data_term = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/tu_input_for_ml_term_inter.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Select The Prediction Target\n",
    "y = ml_data_term[\"Operonic to IUN\"]\n",
    "# display(y)\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"GOntoSim Similarity to IUN\", \"Upstream Terminator Inter\"]\n",
    "X_4f = ml_data_term[ml_features]\n",
    "display(X_4f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "796d4dc5-0956-4633-aa9b-eb25d7711c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__bootstrap': True, 'model__max_depth': 10, 'model__max_features': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10}\n",
      "Best CV score: 0.8164551515046752\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning (Setting up a GridSearchCV)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_features': [1, 2, 3, 4, None],\n",
    "    'model__max_depth': [2, 6, 10, None],\n",
    "    'model__min_samples_leaf': [1, 2, 5, 10, 0.05, 0.1],\n",
    "    'model__min_samples_split': [2, 5, 10, 0.05, 0.1, 0.2],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_inner,\n",
    "    # scoring=\"f1\",   # or 'balanced_accuracy' if positives/negatives equally important\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_4f, y)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e856dc7b-3617-4d85-a93d-03a1be85da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.840\n",
      "CV Precision:        0.879\n",
      "CV Recall:           0.898\n",
      "CV F1‐Score:         0.889\n",
      "CV ROC AUC:          0.910\n",
      "CV Log‐Loss:         0.399\n",
      "CV Brier Score:      0.110\n",
      "CV Confusion Matrix:\n",
      " [[117  51]\n",
      " [ 42 371]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (4 features, no Wang Similarity to IUN) and tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=10, max_features=3, min_samples_leaf=2, min_samples_split=10, random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X_4f, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba_no_wang = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred_no_wang = (pos_proba_no_wang >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred_no_wang)\n",
    "prec  = precision_score(y, y_pred_no_wang)\n",
    "rec   = recall_score(y, y_pred_no_wang)\n",
    "f1    = f1_score(y, y_pred_no_wang)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred_no_wang)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97155e97-8a0c-46c6-a286-04e8f4b7d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred, y_pred_no_wang, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a11fcc51-2acf-40e5-bd2f-d63c45c6ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar’s χ² = 6.000, p-value = 0.332\n"
     ]
    }
   ],
   "source": [
    "# Run McNemar’s test comparision between 6-feature and 4-feature models\n",
    "\n",
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# model A: y_pred (6 features, tuned)\n",
    "# model B: y_pred_no_wang (4 features, tuned)\n",
    "\n",
    "# Build the 2×2 table\n",
    "# n01 = A correct, B wrong\n",
    "# n10 = A wrong,   B correct\n",
    "n01 = np.sum((y_pred == y) & (y_pred_no_wang != y))\n",
    "n10 = np.sum((y_pred != y) & (y_pred_no_wang == y))\n",
    "table = [[0, n01],\n",
    "         [n10, 0]]\n",
    "\n",
    "# Run McNemar’s test (exact if sample small, else use chi2)\n",
    "result = mcnemar(table, exact=True)\n",
    "print(f\"McNemar’s χ² = {result.statistic:.3f}, p-value = {result.pvalue:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67404337-9039-474c-9d63-84a3ebf31aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0\n",
      " 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0\n",
      " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0\n",
      " 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
      " 1 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1] [0.51394441 0.38560576 0.95454595 0.79141595 0.57252046 0.74548976\n",
      " 0.10388015 0.44473089 1.         0.78277815 1.         0.999\n",
      " 0.98202767 0.999      1.         1.         0.01352758 0.0546195\n",
      " 0.61299979 0.13393069 0.06179976 0.02979526 0.01904584 0.31851216\n",
      " 0.45037493 0.99823077 0.34377426 0.08323771 0.74524447 0.13500552\n",
      " 1.         0.95287928 0.7695749  0.43659196 0.19849992 0.82239763\n",
      " 0.26319731 0.74402591 0.07624287 1.         0.34521687 0.9978022\n",
      " 0.11167516 0.79215587 0.278826   0.39003331 0.033398   0.81833331\n",
      " 0.98137363 0.98115934 0.2820959  1.         0.15269185 0.99923077\n",
      " 0.3105659  0.84159555 0.39765383 0.70833292 1.         0.30304896\n",
      " 1.         0.05797197 0.97102767 0.76296506 1.         0.98202767\n",
      " 0.94264774 1.         0.05602129 0.01203186 0.49250575 1.\n",
      " 1.         1.         0.20651382 1.         0.13126963 0.16034535\n",
      " 0.70536774 0.99775    0.999      1.         0.25428711 0.99923077\n",
      " 0.1556099  0.90420299 0.11876272 0.99746591 0.96351648 1.\n",
      " 0.88039763 1.         1.         1.         1.         0.27522195\n",
      " 0.36463219 0.26832398 0.44309419 0.9978022  0.66381929 0.34205447\n",
      " 0.02430195 0.32896482 1.         1.         0.71687335 0.20273081\n",
      " 0.77474299 0.21141218 0.64655418 0.32255003 0.38791284 0.999\n",
      " 0.89293926 0.85661078 0.78566225 0.40046732 0.99237363 0.99923077\n",
      " 0.99237363 0.99923077 1.         0.27756273 0.2021316  0.29384741\n",
      " 0.63883601 0.38831314 0.989      1.         0.13519667 0.4746281\n",
      " 0.54247561 0.97846474 0.99714286 0.28647175 0.13773146 0.49763264\n",
      " 0.97077244 0.99368813 1.         0.56673101 0.26035861 0.98520202\n",
      " 1.         1.         0.21720959 0.78694225 1.         0.99565108\n",
      " 0.67995163 0.98817308 0.05448876 1.         1.         0.73569599\n",
      " 0.9075     0.28226535 1.         0.983      0.985      0.04354853\n",
      " 0.62285568 0.68463323 0.76226283 0.18515963 1.         1.\n",
      " 1.         0.99368813 0.99       0.99       0.26614702 0.05507701\n",
      " 0.96058586 0.3525265  0.06602892 0.9975     1.         0.963375\n",
      " 0.98714286 1.         1.         0.87977887 1.         0.49960424\n",
      " 1.         1.         1.         0.49887705 1.         1.\n",
      " 1.         1.         1.         0.77361833 1.         1.\n",
      " 1.         0.82276032 0.95172275 0.41745455 0.70961508 0.51998054\n",
      " 0.91429186 0.13330167 1.         1.         1.         0.8225\n",
      " 0.998      0.25015708 0.74805217 0.50257824 0.0246759  0.27123338\n",
      " 0.50598858 0.37820173 0.94       1.         0.06978491 0.19664322\n",
      " 0.07557906 1.         0.78050329 1.         0.16851627 0.96172275\n",
      " 0.70525436 0.97636364 1.         1.         0.87941696 0.39221418\n",
      " 0.90366074 1.         0.41152575 0.03929543 1.         0.72061179\n",
      " 0.65628724 0.60552565 0.82124208 1.         0.86728674 1.\n",
      " 0.76819339 1.         1.         1.         0.69939669 0.80385275\n",
      " 0.65264605 0.57850032 1.         1.         0.61316525 0.94933333\n",
      " 1.         0.52573719 0.59795983 1.         1.         1.\n",
      " 1.         1.         1.         0.99714286 1.         0.15273893\n",
      " 0.07530224 0.20829357 0.61214258 0.95727704 0.47629564 0.29037336\n",
      " 0.78225082 0.5837456  0.17084375 0.40060307 0.99234127 0.28168994\n",
      " 1.         1.         1.         0.82248979 1.         1.\n",
      " 1.         0.53599179 1.         0.76953748 0.483955   1.\n",
      " 0.66129187 0.20705381 0.84093912 1.         0.68096618 1.\n",
      " 0.9110941  0.93389177 1.         0.83193305 0.72617939 0.82042542\n",
      " 0.82693305 0.02588128 0.97700758 0.01671999 1.         1.\n",
      " 1.         0.8777152  0.94933333 0.84644739 1.         1.\n",
      " 1.         1.         0.06978491 0.61173072 0.7974675  1.\n",
      " 1.         0.79784686 0.72634511 0.8901766  0.9020756  1.\n",
      " 1.         1.         1.         1.         0.91881367 1.\n",
      " 0.79153131 0.32754053 1.         0.41758032 0.31804878 0.03303979\n",
      " 0.06256542 1.         0.08671212 1.         0.22787624 1.\n",
      " 1.         0.985      0.64469537 0.76457295 1.         1.\n",
      " 1.         1.         1.         0.79426244 1.         0.02720964\n",
      " 0.53515582 0.35751125 0.998      0.99952381 1.         0.96208297\n",
      " 0.27197335 0.99423077 0.17743672 1.         0.96444388 0.17176876\n",
      " 1.         0.34106129 0.99518182 0.50540623 0.91717596 0.14372267\n",
      " 0.97376768 1.         0.70041268 0.21697094 0.40791561 0.94566667\n",
      " 1.         0.97034712 0.74355005 0.82982179 0.75757295 0.54485007\n",
      " 0.38043837 0.38190984 0.65975469 0.95039211 0.90056841 0.96727894\n",
      " 1.         1.         1.         0.99818182 0.813671   0.25538014\n",
      " 0.18164039 0.99266667 1.         0.51176513 0.34906675 0.71007271\n",
      " 0.29997348 1.         0.91398773 0.02165349 0.3607608  0.88636869\n",
      " 0.56979302 0.01204888 0.99493773 0.66194303 0.99952381 1.\n",
      " 0.91336869 0.9851044  0.95607565 1.         1.         1.\n",
      " 0.95493434 1.         0.985      0.6982687  1.         1.\n",
      " 0.99493773 1.         0.99623077 1.         0.58907064 0.\n",
      " 0.75612524 0.84680504 1.         0.94446154 1.         0.68053898\n",
      " 0.73316774 1.         0.61331555 0.69545349 0.61678365 1.\n",
      " 0.9119817  1.         1.         0.91237912 0.96753535 1.\n",
      " 0.99923077 0.99472222 1.         0.92233823 0.14369158 0.55427519\n",
      " 0.3607608  0.35078739 0.19652193 0.32283876 0.995      0.18680596\n",
      " 0.1984564  0.74636516 0.07747594 0.05211097 0.16202756 0.88644964\n",
      " 0.37114708 1.         0.99584416 0.58230762 0.77302718 0.21423253\n",
      " 0.48735912 0.3471351  0.51330297 0.82245196 1.         1.\n",
      " 0.37875477 0.54125104 1.         0.22200994 0.02211097 0.05549975\n",
      " 0.64911775 0.47705472 0.33630796 0.40761645 0.96957204 0.96428592\n",
      " 0.87111694 0.76476071 1.         0.38803674 0.60107297 0.40792455\n",
      " 1.         1.         1.         1.         1.         0.8766725\n",
      " 1.         1.         1.         0.9232856  1.         1.\n",
      " 1.         1.         1.         1.         0.99805556 1.\n",
      " 1.         1.         1.         0.20969598 0.08438681 0.58161896\n",
      " 0.90754063 0.00932251 0.50322128 1.         0.28060251 0.84100494\n",
      " 0.00698918 0.85778485 0.64554084 0.74185379 0.8915925  1.\n",
      " 0.98333333 0.91039286 0.23148229 1.         0.80204757 0.49662655\n",
      " 0.95280941 1.         0.74120838 0.99584416 1.         0.99584416\n",
      " 1.         1.         0.051991   1.         0.87116911 0.11267804\n",
      " 0.52120149 0.11069983 0.33801901 1.         0.04819474 0.20033235\n",
      " 0.52494653 0.93181259 0.83451648 0.10280839 0.96120024 0.99805556\n",
      " 0.1007952  0.89054305 1.         0.57285697 1.         0.2740116\n",
      " 0.82523354 0.85556183 1.         1.         1.        ] [0.45799903 0.53081185 0.93677456 0.78585734 0.56677494 0.76520332\n",
      " 0.08990361 0.49126429 1.         0.75982657 1.         0.99474026\n",
      " 1.         0.99474026 1.         1.         0.04829537 0.03545188\n",
      " 0.56841527 0.14946832 0.0615441  0.06388145 0.01730939 0.3437377\n",
      " 0.57773702 0.99090909 0.29376156 0.08467354 0.6777238  0.16636309\n",
      " 1.         0.95073921 0.80901793 0.46410592 0.34373307 0.92049201\n",
      " 0.27065059 0.72496484 0.05741556 0.98975    0.26699919 0.98381731\n",
      " 0.08385908 0.73819701 0.38447645 0.35135692 0.0531087  0.78177931\n",
      " 0.97876623 0.99079167 0.35277467 1.         0.24932334 1.\n",
      " 0.33611016 0.85075677 0.41118322 0.65722698 1.         0.34445199\n",
      " 1.         0.07604545 0.99474026 0.74623196 1.         0.97964899\n",
      " 0.88301399 1.         0.05825155 0.05716754 0.5690092  1.\n",
      " 1.         1.         0.18091969 1.         0.25769645 0.17653094\n",
      " 0.61980956 0.96118506 0.98205594 0.99857143 0.25467768 0.991\n",
      " 0.11456984 0.90013596 0.09365072 0.99682217 0.98091667 0.99569231\n",
      " 0.93049201 1.         1.         1.         1.         0.26795672\n",
      " 0.41064516 0.54643299 0.52546988 0.97531944 0.68471118 0.40531875\n",
      " 0.06202645 0.42368836 1.         1.         0.70640755 0.27726442\n",
      " 0.71900221 0.21678286 0.71223516 0.37345486 0.44127183 0.99928571\n",
      " 0.84758098 0.8547494  0.8547494  0.4173801  0.99785714 1.\n",
      " 1.         0.987      1.         0.22524458 0.2177196  0.34218375\n",
      " 0.74045992 0.26217993 0.99928571 1.         0.08817344 0.46448191\n",
      " 0.52224504 0.9674053  1.         0.36000566 0.08928337 0.5449554\n",
      " 0.96407197 1.         1.         0.57963366 0.30001597 0.95510323\n",
      " 1.         1.         0.2524952  0.75977123 1.         0.99264793\n",
      " 0.68778499 0.98473834 0.07033104 1.         1.         0.76697649\n",
      " 0.92955556 0.18178714 1.         0.997      0.99157143 0.01540199\n",
      " 0.6976312  0.66010473 0.7132771  0.16947684 1.         1.\n",
      " 1.         1.         0.995      0.99157143 0.20442992 0.08420916\n",
      " 0.94985506 0.37747193 0.08972518 0.98570513 1.         0.94011524\n",
      " 0.99666667 1.         1.         0.82832426 1.         0.51878594\n",
      " 1.         1.         1.         0.57591162 1.         1.\n",
      " 1.         1.         1.         0.74751249 1.         1.\n",
      " 1.         0.78927325 0.92428222 0.46424946 0.78042677 0.5620378\n",
      " 0.87443468 0.1448348  1.         1.         0.98071429 0.932\n",
      " 1.         0.24640733 0.70128769 0.46967561 0.02583281 0.24524529\n",
      " 0.51159966 0.31402225 0.932      1.         0.09235977 0.20777397\n",
      " 0.08114794 1.         0.73117643 1.         0.16271423 0.93879202\n",
      " 0.68366541 0.97559926 1.         1.         0.89010419 0.42726533\n",
      " 0.87531196 0.99857143 0.3964683  0.03912865 1.         0.65552478\n",
      " 0.63162193 0.6088259  0.7069198  1.         0.82370133 1.\n",
      " 0.71444017 1.         1.         1.         0.81079692 0.79607098\n",
      " 0.52610863 0.49555788 1.         1.         0.56595819 0.95775758\n",
      " 1.         0.55255593 0.60669498 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.13396861\n",
      " 0.08227022 0.24179777 0.65031362 0.93483613 0.49510279 0.27777765\n",
      " 0.75252805 0.57845855 0.16693312 0.43536851 0.98652778 0.2140078\n",
      " 1.         1.         1.         0.84688239 1.         1.\n",
      " 0.99175    0.55689221 0.99875    0.85961514 0.37530366 1.\n",
      " 0.62971924 0.2269423  0.86035317 0.98492424 0.77202311 1.\n",
      " 0.86727101 0.98472872 1.         0.83021456 0.75552805 0.79936535\n",
      " 0.82421456 0.05529778 0.95649062 0.03688978 1.         1.\n",
      " 1.         0.87840287 0.95775758 0.85647619 1.         1.\n",
      " 1.         1.         0.09235977 0.61125431 0.72152643 1.\n",
      " 1.         0.82048631 0.6854778  0.8874537  0.84508985 1.\n",
      " 1.         1.         1.         0.99659091 0.9395201  0.99659091\n",
      " 0.70148257 0.32615597 1.         0.43597845 0.3421153  0.05035409\n",
      " 0.10924161 1.         0.08465657 0.99095238 0.31062291 1.\n",
      " 0.99857143 0.99239496 0.69286347 0.70789913 1.         1.\n",
      " 1.         1.         1.         0.76736948 1.         0.08616599\n",
      " 0.53502785 0.36579634 0.99607143 0.99780702 0.9975     0.93492854\n",
      " 0.2729448  0.99440476 0.16603037 1.         0.94314501 0.16178813\n",
      " 0.9975     0.38147033 0.98552706 0.53631859 0.86120788 0.14694519\n",
      " 0.95737845 0.9975     0.70841986 0.23031686 0.36216313 0.97712088\n",
      " 1.         0.93740452 0.70512526 0.92275285 0.70337348 0.47697002\n",
      " 0.25213897 0.25534853 0.67757136 0.9378994  0.87042583 0.96792965\n",
      " 1.         1.         1.         0.98404401 0.89421609 0.21673303\n",
      " 0.31820466 0.99690476 0.99545455 0.45486604 0.37368509 0.70265175\n",
      " 0.28254762 1.         0.93022657 0.02325372 0.41080079 0.95904575\n",
      " 0.71305839 0.02239553 1.         0.61605483 0.99947368 0.99333333\n",
      " 0.96595051 0.99690476 0.98484445 1.         1.         1.\n",
      " 1.         1.         0.99382353 0.68132136 1.         1.\n",
      " 1.         1.         0.99690476 1.         0.49618879 0.\n",
      " 0.77345552 0.78694186 1.         0.99947368 1.         0.68315184\n",
      " 0.7300128  1.         0.69389443 0.8895182  0.5040359  1.\n",
      " 0.93308596 1.         1.         0.90889286 0.99437908 1.\n",
      " 0.99909091 0.97980952 1.         0.90799737 0.13545137 0.55609774\n",
      " 0.41080079 0.32723023 0.12889717 0.36939324 0.99833333 0.10754281\n",
      " 0.23310854 0.68238834 0.07810948 0.05071309 0.18278209 0.8919699\n",
      " 0.34928068 1.         0.98857143 0.47995544 0.69816685 0.21677585\n",
      " 0.43855907 0.31226935 0.50335336 0.81598043 1.         1.\n",
      " 0.31733234 0.53949159 1.         0.20879003 0.05071309 0.06897456\n",
      " 0.66090909 0.55828316 0.33026762 0.412429   0.98644134 0.96137159\n",
      " 0.90846512 0.87458449 1.         0.47072022 0.59917644 0.26322237\n",
      " 1.         1.         1.         1.         1.         0.9054294\n",
      " 1.         1.         1.         0.9571657  1.         1.\n",
      " 1.         1.         1.         1.         0.98380952 1.\n",
      " 1.         1.         1.         0.26319041 0.11079271 0.64703562\n",
      " 0.9280362  0.02150186 0.59830422 1.         0.27062984 0.88304545\n",
      " 0.01039401 0.80072333 0.60304887 0.79090758 0.8919699  1.\n",
      " 0.98492063 0.88863656 0.11411342 1.         0.77968282 0.53455748\n",
      " 0.96333236 0.99571429 0.68401341 0.99857143 1.         0.99857143\n",
      " 0.98666667 1.         0.10281456 1.         0.86854094 0.18340911\n",
      " 0.56186128 0.11747394 0.31871407 1.         0.06092374 0.17852432\n",
      " 0.55732362 0.93524315 0.86873377 0.1054774  0.92158206 0.99769231\n",
      " 0.12404608 0.85040241 1.         0.57586128 1.         0.27062984\n",
      " 0.80515774 0.83940415 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(y, pos_proba, pos_proba_no_wang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c699c036-1002-4a6b-a9ca-8702c73cc801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeLong’s test p-value = 0.1215\n"
     ]
    }
   ],
   "source": [
    "# Run DeLong’s test between 6-feature and 4-feature models\n",
    "\n",
    "import numpy as np\n",
    "from rocauc_comparison import delong_roc_test\n",
    "\n",
    "# y_true: 0/1 ground truth\n",
    "# y_scores_A, y_scores_B: real-valued scores (probabilities or decision function)\n",
    "p_value = 10 ** delong_roc_test(y, pos_proba, pos_proba_no_wang).item()\n",
    "print(f\"DeLong’s test p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90e9cf4f-9829-48a2-a0c1-8a96c8aeb987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance to IUN</th>\n",
       "      <th>Hamming Distance to IUN</th>\n",
       "      <th>Wang Similarity to IUN</th>\n",
       "      <th>Upstream Terminator Inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>575</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>0.478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>123</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>122</td>\n",
       "      <td>0.130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>31</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distance to IUN  Hamming Distance to IUN  Wang Similarity to IUN  \\\n",
       "0                575                    0.043                   0.735   \n",
       "1                134                    0.043                     NaN   \n",
       "2                174                    0.043                   0.901   \n",
       "3                 68                    0.043                     NaN   \n",
       "4                105                    0.478                     NaN   \n",
       "..               ...                      ...                     ...   \n",
       "576              123                    0.130                     NaN   \n",
       "577              122                    0.130                     NaN   \n",
       "578               -1                    0.000                     NaN   \n",
       "579                3                    0.087                     NaN   \n",
       "580               31                    0.087                   0.514   \n",
       "\n",
       "     Upstream Terminator Inter  \n",
       "0                            1  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "..                         ...  \n",
       "576                          0  \n",
       "577                          0  \n",
       "578                          0  \n",
       "579                          0  \n",
       "580                          0  \n",
       "\n",
       "[581 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ml_data_term = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/tu_input_for_ml_term_inter.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Select The Prediction Target\n",
    "y = ml_data_term[\"Operonic to IUN\"]\n",
    "# display(y)\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN\", \"Wang Similarity to IUN\", \"Upstream Terminator Inter\"]\n",
    "X = ml_data_term[ml_features]\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deb864cc-39c4-4c69-96b8-269cd55eb5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__bootstrap': True, 'model__max_depth': 10, 'model__max_features': 4, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10}\n",
      "Best CV score: 0.8075865742872363\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning (Setting up a GridSearchCV)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_features': [1, 2, 3, 4, None],\n",
    "    'model__max_depth': [2, 6, 10, None],\n",
    "    'model__min_samples_leaf': [1, 2, 5, 10, 0.05, 0.1],\n",
    "    'model__min_samples_split': [2, 5, 10, 0.05, 0.1, 0.2],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_inner,\n",
    "    # scoring=\"f1\",   # or 'balanced_accuracy' if positives/negatives equally important\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0502063c-de2c-43a4-8bde-136815d5216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.835\n",
      "CV Precision:        0.876\n",
      "CV Recall:           0.893\n",
      "CV F1‐Score:         0.885\n",
      "CV ROC AUC:          0.909\n",
      "CV Log‐Loss:         0.400\n",
      "CV Brier Score:      0.111\n",
      "CV Confusion Matrix:\n",
      " [[116  52]\n",
      " [ 44 369]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (4 features, no GOntoSim Similarity to IUN) and tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=10, max_features=4, min_samples_leaf=2, min_samples_split=10, random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1aabdb-38af-42a1-8ba0-57b1c18b2536",
   "metadata": {},
   "source": [
    "This model is slightly worse than the model based on GOntoSim Similarity to IUN. Therefore, we retain four features (excluding Wang Similarity to IUN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c7c52-c834-48f7-8fb6-5e1945e1380f",
   "metadata": {},
   "source": [
    "Since interspecific Hamming distances won't allow to obtain information about genes in non-reference genomes, I therefore performed phylogenetic profiling for all complete B. breve genomes and added the updated data to the training df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe121b8-09bc-48be-a01e-6550f3481cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ml_data_term = pd.read_csv(\"/home/msdyachkova/data15/bifido/operon_prediction/tu_input_for_ml_hamming_intrasp.tsv\", sep=\"\\t\").set_index(\"Protein ID\")\n",
    "\n",
    "# Select The Prediction Target\n",
    "y = ml_data_term[\"Operonic to IUN\"]\n",
    "# display(y)\n",
    "\n",
    "# Select Features\n",
    "ml_features = [\"Distance to IUN\", \"Hamming Distance to IUN Intra\", \"Wang Similarity to IUN\", \"Upstream Terminator Inter\"]\n",
    "X = ml_data_term[ml_features]\n",
    "# display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe58c825-f6c6-4cba-94d4-8b4bd8630681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__bootstrap': True, 'model__max_depth': None, 'model__max_features': 1, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10}\n",
      "Best CV score: 0.8101815897999197\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning (Setting up a GridSearchCV)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_features': [1, 2, 3, 4, None],\n",
    "    'model__max_depth': [2, 6, 10, None],\n",
    "    'model__min_samples_leaf': [1, 2, 5, 10, 0.05, 0.1],\n",
    "    'model__min_samples_split': [2, 5, 10, 0.05, 0.1, 0.2],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_inner,\n",
    "    # scoring=\"f1\",   # or 'balanced_accuracy' if positives/negatives equally important\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    # verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8029ae79-0a3d-40ba-86f6-d7cf120d66b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.843\n",
      "CV Precision:        0.878\n",
      "CV Recall:           0.906\n",
      "CV F1‐Score:         0.892\n",
      "CV ROC AUC:          0.908\n",
      "CV Log‐Loss:         0.343\n",
      "CV Brier Score:      0.112\n",
      "CV Confusion Matrix:\n",
      " [[116  52]\n",
      " [ 39 374]]\n"
     ]
    }
   ],
   "source": [
    "# BEST MODEL\n",
    "# Random Forest Classifier with cross-validation (4 features) and tuned hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=None, max_features=1, min_samples_leaf=2, min_samples_split=10, random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327844f5-0d33-4730-adac-8e8423db5d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy:         0.826\n",
      "CV Precision:        0.898\n",
      "CV Recall:           0.852\n",
      "CV F1‐Score:         0.875\n",
      "CV ROC AUC:          0.908\n",
      "CV Log‐Loss:         0.353\n",
      "CV Brier Score:      0.115\n",
      "CV Confusion Matrix:\n",
      " [[128  40]\n",
      " [ 61 352]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with cross-validation (4 features) and tuned hyperparameters w balanced class weight\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, log_loss, brier_score_loss,\n",
    "    confusion_matrix)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=None, max_features=1, min_samples_leaf=2, min_samples_split=10, class_weight='balanced', random_state=1))\n",
    "])\n",
    "\n",
    "# 1) Get out‑of‑fold probabilities\n",
    "proba = cross_val_predict(\n",
    "    pipeline, X, y,\n",
    "    cv=5,\n",
    "    method='predict_proba') # predict_proba returns an array of shape (n_samples, n_classes)\n",
    "\n",
    "pos_proba = proba[:, 1] # [:,0] = P(class=0), [:,1] = P(class=1)\n",
    "# print(pos_proba)\n",
    "\n",
    "# 2) Get out‑of‑fold class predictions (threshold = 0.5)\n",
    "y_pred = (pos_proba >= 0.5).astype(int)\n",
    "y = y.to_numpy()\n",
    "\n",
    "# 3) Compute metrics on the whole dataset using OOF predictions\n",
    "acc   = accuracy_score(y, y_pred)\n",
    "prec  = precision_score(y, y_pred)\n",
    "rec   = recall_score(y, y_pred)\n",
    "f1    = f1_score(y, y_pred)\n",
    "auc   = roc_auc_score(y, pos_proba)\n",
    "ll    = log_loss(y, pos_proba)\n",
    "brier = brier_score_loss(y, pos_proba)\n",
    "cm    = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy:         {acc:.3f}\")\n",
    "print(f\"CV Precision:        {prec:.3f}\")\n",
    "print(f\"CV Recall:           {rec:.3f}\")\n",
    "print(f\"CV F1‐Score:         {f1:.3f}\")\n",
    "print(f\"CV ROC AUC:          {auc:.3f}\")\n",
    "print(f\"CV Log‐Loss:         {ll:.3f}\")\n",
    "print(f\"CV Brier Score:      {brier:.3f}\")\n",
    "print(\"CV Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygenomeviz",
   "language": "python",
   "name": "pygenomeviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
